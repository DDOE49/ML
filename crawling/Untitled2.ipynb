{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daum_news_title(news_id):\n",
    "    url = 'https://news.v.daum.net/v/{}'.format(news_id)\n",
    "    resp = requests.get(url)\n",
    "    \n",
    "    soup = BeautifulSoup(resp.text)\n",
    "    \n",
    "    title_tag = soup.select_one('h3.tit_view')\n",
    "    if title_tag:\n",
    "        return title_tag.get_text()\n",
    "    return\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'댓글 조작' 김경수 징역 2년 확정..지사직 박탈\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_daum_news_title(20210721104401263)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daum_news_title(news_id):\n",
    "    url = 'https://news.v.daum.net/v/{}'.format(news_id)\n",
    "    resp = requests.get(url)\n",
    "    \n",
    "    soup = BeautifulSoup(resp.text)\n",
    "    \n",
    "    content = ''\n",
    "    for p in soup.select('div#harmonyContainer p'):\n",
    "        content += p.get_text()\n",
    "        \n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[아시아경제 이민우 기자] 일론 머스크 테슬라 최고경영자(CEO)가 자사 전기 자동차 모델에 넷플릭스와 유튜브 등 온라인동영상서비스(OTT)를 탑재할 것이라고 예고했다. 단순히 자율 주행 전기차가 단순히 주행을 위한 정보를 알려주는 것을 넘어 각종 영상 콘텐츠를 즐기는 공간으로도 확장하겠다는 전략으로 풀이된다.27일(현지시간) 더버지 등 주요 외신들에 따르면 머스크 CEO는 자신의 트위터를 통해 이 같은 계획을 밝혔다. 그는 \"자동차가 정차했을 때 넷플릭스와 유튜브를 감상할 수 있는 기능이 조만간 추가될 것\"이라며 \"편안한 좌석과 서라운드 사운드 오디오를 통해 영화관과 같은 느낌을 받을 수 있을 것\"이라고 강조했다.테슬라가 이처럼 콘텐츠 방면으로 확장하려 든 것은 이번이 처음이 아니다. 지난달 세계 최대 게임쇼 E3에서는 이미 운전자가 \\'폴아웃 쉘터\\'라는 게임을 할 수 있을 것이라고 발표한 바 있다. 이후에도 최근 게임업체 아타리사(社)의 자동차 경주 게임 ‘폴포지션’, 슈팅게임 ‘템페스트’, ‘미사일커맨드’ 등 고전 게임을 제공하기도 했다. 운전대로 게임을 조작하는 방식으로, 차가 주차돼 있을 경우에만 즐길 수 있다.이번 영상 콘텐츠는 주행 중에도 감상할 수 있도록 하는 방안을 고려하고 있다. 테슬라 측은 규제당국이 자율주행에 대해 완전히 승인하면 차량이 움직일 때에도 승객이 동영상을 즐길 수 있을 것이라고 설명했다.하지만 아직까지 자율주행차의 안전에 대한 우려는 완전히 걷혀지지 않은 상황이다. 지난 2017년 차량공유 서비스 우버의 자율주행 시범차량이 보행자와 충돌한 사고가 발생한 바 있다. 게다가 당시 시험 운전자는 디즈니의 동영상 스트리밍 서비스인 \\'훌루\\'를 이용하고 있던 것으로 밝혀졌다.이민우 기자 letzwin@asiae.co.kr<ⓒ경제를 보는 눈, 세계를 보는 창 아시아경제 무단전재 배포금지>'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_daum_news_title(20190728165812603)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#네이버금융종목토론방게시글 크롤링\n",
    "\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from datetime import date, timedelta, datetime\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import dask.dataframe as dd\n",
    "from random import randint\n",
    "from time import sleep\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import requests\n",
    "import shutil\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# path\n",
    "dir_path='C:/Users/111/naver_stock_crowling'\n",
    "# 크롬드라이버 path\n",
    "path = \"C:/Users/111/Documents/chromedriver_win32/chromedriver.exe\"\n",
    "driver = webdriver.Chrome(path)\n",
    "sleep(randint(10, 20) / 10)\n",
    "driver.get(\"http://data.krx.co.kr/contents/MDC/MDI/mdiLoader/index.cmd?menuId=MDC0201020101\")\n",
    "sleep(randint(10, 20) / 2)\n",
    "driver.find_element_by_css_selector('button.CI-MDI-UNIT-DOWNLOAD').click()\n",
    "sleep(randint(10, 20) / 10)\n",
    "driver.find_elements_by_xpath(\"//div[@class='filedown_wrap']/div[@data-type='csv']\")[0].click()\n",
    "sleep(randint(10, 20) / 10)\n",
    "stock_code=glob('C:/Users/111/Downloads/data*.csv')\n",
    "codelist_path=dir_path+'/codelist/codelist_'+stock_code[0].split('\\\\')[-1].split('_')[-1]\n",
    "if len(stock_code)==1:\n",
    "    shutil.move(stock_code[0],codelist_path)\n",
    "    \n",
    "else :\n",
    "    print(\"다운로드 폴더를 확인해주세요\")\n",
    "#    break\n",
    "\n",
    "#C:\\Users\\111\\naver_stock_crowling\n",
    "#shutil.move(src + filename, dir + filename)\n",
    "\n",
    "\n",
    "codelist=pd.read_csv(codelist_path,encoding='euc-kr')\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(list(codelist['종목코드'])))):\n",
    "    final_df=pd.DataFrame()\n",
    "\n",
    "    S_code=list(codelist['종목코드'])[i]\n",
    "    S_name=list(codelist['종목명'])[i]\n",
    "    driver.get(\"https://finance.naver.com/item/board.nhn?code=\"+S_code)\n",
    "\n",
    "    for Num in range(0,int(str(BeautifulSoup(driver.page_source,'html.parser').select('td.pgRR')).split('\">')[1].split('=')[-1])+1):\n",
    "        driver.get(\"https://finance.naver.com/item/board.nhn?code=\"+S_code+'&page='+str(Num))\n",
    "\n",
    "\n",
    "    #    if not os.path.isdir(dir_path+'/data/'+S_name): \n",
    "    #        os.makedirs(dir_path+'/data/'+S_name)\n",
    "    #    debate_list=glob(dir_path+'/data/'+S_name+'/*')\n",
    "\n",
    "        texts=str(BeautifulSoup(driver.page_source,'html.parser').select('table.type2'))\n",
    "        texts=texts.split('onmouseover')[1:]\n",
    "        time=list(map(lambda x:x.split('</span>')[0].split('>')[-1],texts))\n",
    "        url=list(map(lambda x:'https://finance.naver.com'+re.sub(\"amp;\",\"\",x.split('href=\"')[1].split('\" onclick')[0]),texts))\n",
    "        title=list(map(lambda x:\"\".join(x.split('title=\"')[1:]).split('\"')[0],texts))\n",
    "        writer=list(map(lambda x:re.sub('[\\n\\t]',\"\",x.split('title=\"')[-1].split('<td class=\"p11\">')[1].split('</td>')[0]),texts))\n",
    "        view=list(map(lambda x:x.split('title=\"')[-1].split('<td class=\"p11\">')[1].split('</span')[0].split(\">\")[-1],texts))\n",
    "        like=list(map(lambda x:x.split('</strong>')[0].split('>')[-1],texts))\n",
    "        unlike=list(map(lambda x:x.split('</strong>')[1].split('>')[-1],texts))\n",
    "\n",
    "\n",
    "\n",
    "        mk_df=pd.DataFrame({\"date\":time,\"url\":url,\"title\":title,\"writer\":writer,\"view\":view,\"like\":like,\"unlike\":unlike})\n",
    "\n",
    "\n",
    "        main_texts=[]\n",
    "        comment=[]\n",
    "        crowlingtime=[]\n",
    "\n",
    "        for url in list(mk_df['url']):\n",
    "            crowlingtime.append(str(datetime.now()))\n",
    "            try:\n",
    "                sleep(randint(10, 20) / 10)\n",
    "                driver.get(url)\n",
    "                while len(driver.page_source.split('댓글 로딩에 실패하였습니다.'))==2:\n",
    "                    sleep(randint(10, 20) / 10)\n",
    "                    driver.find_element_by_css_selector('span.u_cbox_txt_refresh').click()\n",
    "\n",
    "                main_text_list=str(BeautifulSoup(driver.page_source,'html.parser').select('div.scr01')[0])\n",
    "                main_texts.append(\"\".join(re.sub(\"</div>\\n</div>\",\"\",re.sub('\\n<br/>',' ',main_text_list)).split('>')[2:]))\n",
    "\n",
    "                users=list(map(lambda x:str(x).split('>')[1].split('<')[0],BeautifulSoup(driver.page_source,'html.parser').select('span.u_cbox_nick')))\n",
    "                ret=list(map(lambda x:str(x).split('>')[1].split('<')[0],BeautifulSoup(driver.page_source,'html.parser').select('span.u_cbox_contents')))\n",
    "                time=list(map(lambda x:str(x).split('>')[1].split('<')[0],BeautifulSoup(driver.page_source,'html.parser').select('span.u_cbox_date')))\n",
    "                comment.append(\"@SPLIT@\".join(list(map(lambda x,y,z:x+'_'+y+'_'+z,users,ret,time))))\n",
    "            except:\n",
    "                main_texts.append(\"Error\")\n",
    "                comment.append(\"Error\")\n",
    "\n",
    "        merge_df=pd.concat([mk_df,pd.DataFrame({'crowlingtime':crowlingtime,'main_texts':main_texts,'comment':comment})],axis=1)    \n",
    "        final_df=pd.concat([final_df,merge_df]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "    \n",
    "    final_df.to_csv(dir_path+'/data/'+S_code+'.csv',encoding=\"utf-8-sig\")\n",
    "#texts=re.sub(\"<th>\",\"\",texts)\n",
    "#re.sub(\"</th>\",\"\",texts)\n",
    "          \n",
    "          "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
